#!/usr/bin/env python
from logging import error
import matplotlib.pylab as plt
import roslib 
import numpy as np
import cv2
import rospy
import sys 
from cv_bridge import CvBridge,CvBridgeError 
from geometry_msgs.msg import Twist 
from sensor_msgs.msg import Image 
from std_msgs.msg import String 



#class defined as calibration
class Calibration(object):
    
    def __init__(self):
        #the final goal of this file is to publish a regrassion line equation
        # in form : robot_frame = m* robot_frame +c 
        # "m" and "c" are the message in float32
        self.regrassion_eqa_pub = rospy.Publisher('/regression_line',queue_size=10)
        
        
        #Initialise CV bridge 
        self.bridge_object = CvBridge()
        # File would read raw rgb image for further processing 
        self.image_sub = rospy.Subscriber("/camera/rgb/image_raw",Image,self.camera_callback)
        
        self.equ_pub_rate = rospy.Rate(10)

    

    def camera_callback(self,data):
        try:
            cv_image =self.bridge_object.imgmsg_to_cv2(data,desired_encoding = "bgr8")
        except CvBridgeError as e:
            print (e)
        #calibration method start here 

	def process_image(pipeline, calibrate):
	    cX = 0
	    cY = 0
	    count = 0
	    camera_coordinates={}
	    rectangles = dict() # store bounding rectangles in the form of dict. key = cX, val = (cY, angle)

	    print("Enter to start")
	    raw_input()

	    ## begin real time detection
	    camera_coordinates={}
	    count += 1
	    print ("================================begin loop "+str(count)+"==============================")
	    pre_frame = pipeline.wait_for_frames()
	    color_frame = pre_frame.get_color_frame()
	    frame = np.asanyarray(color_frame.get_data())

	    depth_frame = pre_frame.get_depth_frame()
	    depth_image = np.asanyarray(depth_frame.get_data())
	    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)

	    ######################## RGB IMAGE PROCESSING ###################################
	    gray_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)

	    #blur = cv2.GaussianBlur(gray_frame,(5,5),cv2.BORDER_DEFAULT)
	    blur = cv2.bilateralFilter(gray_frame,3, 75, 75)

	    thresh,th1 = cv2.threshold(blur,127,255,cv2.THRESH_BINARY)
	    print('threshold used: ' + str(thresh))

	    th2 = cv2.adaptiveThreshold(th1,255,cv2.ADAPTIVE_THRESH_MEAN_C,\
		    cv2.THRESH_BINARY,3,2)
	    th3 = cv2.adaptiveThreshold(th1,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
		    cv2.THRESH_BINARY,3,2)

	    kernel = np.ones((5,5), np.uint8)
	    erosion = cv2.erode(th3,kernel, iterations = 1)
	    _,contours, _ = cv2.findContours(erosion, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

	    cv2.imshow('binary',th1)
	    cv2.imshow('mean',th2)
	    cv2.imshow('gauss',erosion)
	    centre = 0;

	    ####################### BLOCK DETECTION #################################
	    for contour in contours:
		area = cv2.contourArea(contour)

		# area of a block laid flat is around 1400, on its side is 1000
		if area < 900 or area > 2500:
		    continue

		peri = cv2.arcLength(contour,True)
		approx = cv2.approxPolyDP(contour,0.02*peri, True)
		(x,y,w,h) = cv2.boundingRect(approx)

		# find center
		M = cv2.moments(contour)

		temp_x = cX
		temp_y = cY
		cX = int(M["m10"]/M["m00"])
		cY = int(M["m01"]/M["m00"])

		# disregard blocks in the construction site
		if cX >= 260 and cX <= 370 and cY >= 320:
		    continue

		# to avoid double scan
		if (np.abs(temp_x - cX) < 20 and np.abs(temp_y - cY) < 20):
		    continue

		cv2.circle(frame,(cX,cY),7,(0,255,0),-1)
		centre += 1

		# find distance
		distance = depth_frame.get_distance(int(cX),int(cY))

		rect = cv2.minAreaRect(contour)

		# make sure length > width and angle is positive, measured clockwise from vertical and in range (0,180)
		temp_rect = list(rect)
		if rect[1][0] > rect[1][1]:
		    temp_rect_size = list(temp_rect[1])
		    temp_rect_size[0] = rect[1][1]
		    temp_rect_size[1] = rect[1][0]
		    temp_rect[1] = tuple(temp_rect_size)
		    temp_rect[2] = (temp_rect[2] - 90) % 180
		else:
		    temp_rect[2] = temp_rect[2] % 180

		rect = tuple(temp_rect)
		rectangles[rect[0][0]] = (rect[0][1], rect[2])

		box = cv2.boxPoints(rect) # cv2.boxPoints(rect) for OpenCV 3.x
		box = np.int0(box)
		cv2.drawContours(frame,[box],0,(0,0,255),2)
		print("block " + str(len(rectangles)-1) + " X: "+ str(int(rect[0][0])) + ", Y: "+ str(int(rect[0][1])) +
		", w: "+ str(int(rect[1][0])) +", l: "+ str(int(rect[1][1])) +", distance: " + str(distance)+ ", area: " + str(area))

        
    
  

def main():
    
    rospy.init_node('calibration',anonymous = True)
    calibration_method=Calibration()
    try:
        rospy.spin()
    except KeyboardInterrupt :
        print("Shutting down")
    cv2.destroyAllwindows()
    

if __name__=='__main__':
    main()
